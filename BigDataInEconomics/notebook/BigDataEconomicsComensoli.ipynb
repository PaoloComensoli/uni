{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img width=\"600\" src='https://github.com/PaoloComensoli/uni/blob/main/BigDataInEconomics/back.jpg?raw=true'>\n",
        "\n",
        "#Big Data in Economics: Project 1\n",
        "\n",
        "- Student: *Comensoli Paolo, 883147*\n",
        "\n",
        "In this notebook we are going to analyze problem #1, regarding the topic of causality, proposed in the course of Big Data in Economics (Data Science Master Degree), University of Milano Bicocca.\n",
        "\n",
        "The code was implemented using OpenAI's **ChatGPT**. Consequently, the following, can be seen as a **prompt engineering task**. However, not all of the analysis was completely entrusted to the artificial intelligence system, but considerations were made for each step. Therefore, the tool was used to support the analysis.\n",
        "\n",
        "<br/>\n",
        "\n",
        "<img width=\"300\" src='https://miro.medium.com/v2/resize:fit:821/1*i8q5s6Y-_i1HO37li9-rtQ.png'>\n",
        "\n",
        "<br/>\n",
        "\n",
        "The Innobarometer (2009) placed the focus on innovation spending, the role of innovation in public procurement tenders, the effects of public policies and private initiatives to boost innovation, and other strategic trends.\n",
        "\n",
        "https://data.europa.eu/data/datasets/s751_267?locale=en\n",
        "\n",
        "In particular, we are interested in whether there is a relationship between whether or not a company has invested in research and development and whether or not it has introduced innovation, in products, services, marketing strategies, and so on."
      ],
      "metadata": {
        "id": "Z6aHUMhCaqeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to read this notebook?\n",
        "\n",
        "The various steps will follow the proposed exercise outline. Each prompt provided to ChatGPT will be highlighted by the keyword: `Prompt:`. Any errors and corrections made to the provided code will be indicated.\n",
        "\n",
        "</br>\n",
        "\n",
        "For example, after checking that ChatGPT had already minimal knowledge of the innobarometer dataset I provided the following prompt:\n",
        "\n",
        "**Prompt**: You're going to work with a Python notebook. A dataset about innobarometer data was loaded into a dataframe called `df`. Some prompts will be provided and you will have to respond with the code.\n"
      ],
      "metadata": {
        "id": "ZxKpw3sOcc1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading\n",
        "\n",
        "As a first step, we load the provided dataset. We will use a `pandas` dataframe to store the data.\n",
        "\n",
        "**Prompt:** Load the data from the following uri https://raw.githubusercontent.com/PaoloComensoli/uni/main/BigDataInEconomics/data/datar.txt in a dataframe called `df`. Use `;` as delimiter. At the end display the head the dataframe.\n"
      ],
      "metadata": {
        "id": "YSidHNAOLFeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/PaoloComensoli/uni/main/BigDataInEconomics/data/datar.txt'\n",
        "\n",
        "df = pd.read_csv(url, delimiter=';')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "QrAQC7jkhReu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "f54a9281-1a8a-45a2-9241-b8689fb61034"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   phoneid  countid  iw_lang  d1_a  d1_b  d1_c  d1_f  d2  d3  d4  ...  \\\n",
              "0        1        1        1     1     1     1     1   1   1   1  ...   \n",
              "1        2        1        2     1     1     2     2   2   1   2  ...   \n",
              "2        3        1        2     1     1     2     2   3   1   1  ...   \n",
              "3        4        1        2     1     1     1     1   1   1   2  ...   \n",
              "4        5        1        2     1     1     1     1   3   1   1  ...   \n",
              "\n",
              "   av_innexpend  av_innsales  av_innspend  av_innsegm2  av_prodinno  \\\n",
              "0           1.0          1.0            1            1            1   \n",
              "1           1.0          2.0            2            2            1   \n",
              "2           1.0          NaN            1            2            2   \n",
              "3           2.0          1.0            1            1            1   \n",
              "4           1.0          3.0            1            3            1   \n",
              "\n",
              "   av_pubpol  av_procureinno  av_innspendtrend  av_intl  av_ctyp  \n",
              "0          1               1               1.0        1        1  \n",
              "1          2               1               1.0        2        1  \n",
              "2          1               2               1.0        2        1  \n",
              "3          1               2               2.0        1        1  \n",
              "4          1               1               1.0        1        1  \n",
              "\n",
              "[5 rows x 120 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-79beff45-e003-42be-864a-38a7b9585f1a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phoneid</th>\n",
              "      <th>countid</th>\n",
              "      <th>iw_lang</th>\n",
              "      <th>d1_a</th>\n",
              "      <th>d1_b</th>\n",
              "      <th>d1_c</th>\n",
              "      <th>d1_f</th>\n",
              "      <th>d2</th>\n",
              "      <th>d3</th>\n",
              "      <th>d4</th>\n",
              "      <th>...</th>\n",
              "      <th>av_innexpend</th>\n",
              "      <th>av_innsales</th>\n",
              "      <th>av_innspend</th>\n",
              "      <th>av_innsegm2</th>\n",
              "      <th>av_prodinno</th>\n",
              "      <th>av_pubpol</th>\n",
              "      <th>av_procureinno</th>\n",
              "      <th>av_innspendtrend</th>\n",
              "      <th>av_intl</th>\n",
              "      <th>av_ctyp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 120 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79beff45-e003-42be-864a-38a7b9585f1a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-0ab3c2a9-5df7-4db7-b715-fa2e7601f0ca\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ab3c2a9-5df7-4db7-b715-fa2e7601f0ca')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-0ab3c2a9-5df7-4db7-b715-fa2e7601f0ca button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79beff45-e003-42be-864a-38a7b9585f1a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79beff45-e003-42be-864a-38a7b9585f1a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDdHtMpehdIX",
        "outputId": "37f73ed0-066c-412e-9cd8-cae3e36dd937"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5234, 120)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset consists of `5234` observations and `120` variables."
      ],
      "metadata": {
        "id": "X4iBRtolhfzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "In this section we are going to perform some preprocessing operations and filter the original dataset."
      ],
      "metadata": {
        "id": "iReRA-bFiFfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Investment in Research & Development"
      ],
      "metadata": {
        "id": "INC7CtTc0fQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let us consider our treatment variable `Q1_a`. This variable indicates that the firm has invested in research and development. It can take 4 values:\n",
        "- 1: Yes\n",
        "- 2: No\n",
        "- 3: Not Applicable\n",
        "- 4: DK/NA\n",
        "\n",
        "As instructed, for simplicity, we will consider 3 to be a 2, and we can eliminate the missing values. We will also turn the value 2 (and 3) into 0, indicating that it has not invested in research and development, keeping the value 1 to indicate that it has invested."
      ],
      "metadata": {
        "id": "e3v0vVaN4862"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt**: Take the column `q1_a` and remove all the rows that has a value of 4."
      ],
      "metadata": {
        "id": "nhmnKfB8w-7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['q1_a'] != 4]"
      ],
      "metadata": {
        "id": "fnTCJR0EiHIO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt:** Take the column `q1_a` and convert both the values 3 and 2 in 0. Use the `.loc` function."
      ],
      "metadata": {
        "id": "7hCGAPwOz5y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df['q1_a'].isin([3, 2]), 'q1_a'] = 0"
      ],
      "metadata": {
        "id": "IvgOFpUR0Amn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Innovation Intensity Index"
      ],
      "metadata": {
        "id": "bfOCnLxk0RkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point we can build up our index. To construct it we will consider the sum of the variable values from `Q6_a` to `Q6_e`. Again the 3 will be considered equal to the 2 and converted to 0."
      ],
      "metadata": {
        "id": "eYmYZ9oS4_rz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt:** Iterate from column `q6_a` to `q6_e`, and for each column delete all the rows that has a value of 4 and convert both the values 3 and 2 into 0. Use the `.loc` function."
      ],
      "metadata": {
        "id": "x9J7t9KC1ymo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['q6_a', 'q6_b', 'q6_c', 'q6_d', 'q6_e']\n",
        "\n",
        "for column in columns:\n",
        "    df = df.loc[df[column] != 4]\n",
        "    df.loc[df[column].isin([3, 2]), column] = 0"
      ],
      "metadata": {
        "id": "fXw2Q_Ng1yNr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt:** Add a new column called `intensity_score` that is the sum of the values of the columns ranging from  'q6_a' to 'q6_e'"
      ],
      "metadata": {
        "id": "wz7VZCmw17bD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['intensity_score'] = df.loc[:, 'q6_a':'q6_e'].sum(axis=1)"
      ],
      "metadata": {
        "id": "BdPRwH6p16iv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Features\n",
        "\n",
        "Since we are going to use a matching approach we need to optimally select `controls`. As indicated among the variables that should definitely be taken into consideration are the size of the company and its industry."
      ],
      "metadata": {
        "id": "pqJKjWlS29g3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_columns = ['q1_a', 'intensity_score']"
      ],
      "metadata": {
        "id": "s8rAl3ks3zFa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the report, question `D2` answers the question: \"*How many employees does your company have [in your country]*?\". This varible range from the value of 1 (20-49 employees) to 4 (500+). However, in this dataset there is already a variable called `size`.\n",
        "\n",
        "**Prompt:** If in the questionarie we have a variable (D2) indicating the size of the company expressed as the number of employee only in its original country, can a variable called size indicate the real size of the firm globally?\n",
        "\n",
        "**Answer:** Yes, a variable called \"size\" can indicate the real size of the firm globally, even if the original questionnaire has a variable (D2) indicating the size of the company expressed only in its original country.\n",
        "\n",
        "If this were the case, we could then expect the variable `D2` to always be less than or equal to the variable `size`.\n",
        "\n",
        "**Prompt:** Check the number of times the variable `d2` is greater then the variable `size`"
      ],
      "metadata": {
        "id": "kgWTZU7p3vKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = sum(df['d2'] > df['size'])\n",
        "print(\"Number of times 'd2' is greater than 'size':\", count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grThpr-P6zfv",
        "outputId": "db06e302-ea26-4deb-9a2d-72359f0e971e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of times 'd2' is greater than 'size': 1115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This does not seem to be the case, and so they could measure two different quantities. As a result, we can keep both variables."
      ],
      "metadata": {
        "id": "lzdrSNbZ7HyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_columns += ['d2', 'size']"
      ],
      "metadata": {
        "id": "701OCm1r76MU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regarding the industry several variables could come in handy. The `nacecode` column contains the statistical classification of economic activities in the European Community. However, it contains 509 values and may be difficult to handle.\n",
        "\n",
        "Alternatively, we find the variable `nace2dgt`, which contains only the first two digits and thus a higher-level classification. In this case we have 54 different classes.\n",
        "\n",
        "To keep things even simpler, however, we could consider the `activity10` variable, which reduces the classification to far fewer elements. As a check we can see if a class of `nace2dgt` belongs to one and only one class of `activity10`.\n",
        "\n",
        "**Prompt:** For each value of the `activity10` column get all the unique values of the `nace2dgt`.\n",
        "\n"
      ],
      "metadata": {
        "id": "ucJNGMoA8M4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_nace_values = df.groupby('activity10')['nace2dgt'].unique()"
      ],
      "metadata": {
        "id": "xCv4umLa_20I"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(unique_nace_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGDh8pe6_6pT",
        "outputId": "c2ffba9c-d372-468f-9c0f-6780b514b81c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "activity10\n",
            "1.0                    [1, 2, 5, 23, 24, 32]\n",
            "2.0                               [3, 4, 44]\n",
            "3.0                 [6, 7, 8, 9, 11, 28, 36]\n",
            "4.0             [10, 13, 14, 15, 29, 46, 20]\n",
            "5.0                     [12, 16, 17, 19, 20]\n",
            "6.0                         [12, 18, 30, 37]\n",
            "7.0     [21, 22, 31, 35, 45, 48, 49, 53, 54]\n",
            "8.0                     [25, 33, 38, 39, 41]\n",
            "9.0                             [34, 26, 40]\n",
            "10.0                            [27, 43, 47]\n",
            "11.0                        [42, 51, 50, 52]\n",
            "Name: nace2dgt, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As it is possible to see a value of `nace2dgt` belongs to only one class of `activity10`. There are 5 missing values that we can remove and then we can create a dummy variable for each class.\n",
        "\n",
        "**Prompt:** Consider the column called activity10. You will create a dummy variable for each value, with the prexif 'Activity'. Then for each row of the dataframe you should assign the value of 1 to the Activity{index} column corresponding to the value of activity10. For example if the value of activity10 is 3 the column Activity3 will have the value 1 and all the others 0."
      ],
      "metadata": {
        "id": "mEykMeY0AGN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=['activity10'])"
      ],
      "metadata": {
        "id": "j5syMVAyDoIB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['activity10'] = df['activity10'].astype(int) # This first line of code is missing in ChatGPT but it was necessary\n",
        "                                                # otherwise it will create the index as a decimal\n",
        "\n",
        "dummy_variables = pd.get_dummies(df['activity10'], prefix='Activity', prefix_sep='') # prefix_sep='' as a personal preference to not have _\n",
        "df = pd.concat([df, dummy_variables], axis=1)"
      ],
      "metadata": {
        "id": "TazS7ZP1BnqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d8ede8c-0309-4f39-c602-86a4c6c5b1f8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-392bd1d305f0>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['activity10'] = df['activity10'].astype(int) # This first line of code is missing in ChatGPT but it was necessary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_columns += list(dummy_variables.columns)"
      ],
      "metadata": {
        "id": "Wu1NGYEmFohn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other variables might come in helpful. For example, since each nation might have its own policies, the geographical distinction might make sense.\n",
        "\n",
        "Here the variable `countid`, which indicates the id of the country to which the company belongs, comes in handy. As in the previous case we create a dummy variable for each country.\n",
        "\n",
        "**Prompt:** Consider the column called `countid`. You will create a dummy variable for each value, with the prexif 'Country'. Then for each row of the dataframe you should assign the value of 1 to the Country{index} column corresponding to the value of `countid`. For example if the value of countid is 3 the column Country3 will have the value 1 and all the others 0."
      ],
      "metadata": {
        "id": "49YPK5kvDicu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_variables = pd.get_dummies(df['countid'], prefix='Country', prefix_sep='')\n",
        "for column in dummy_variables.columns:\n",
        "    df[column] = np.where(df['countid'] == int(column.split('Country')[1]), 1, 0)"
      ],
      "metadata": {
        "id": "LU2Qlj_ZDJB-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_columns += list(dummy_variables.columns)"
      ],
      "metadata": {
        "id": "z4U91vi3G9Ke"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The age at which the company was established may also help to better match treated and control. Question D3 comes in handy in this case: \"*When was your company established?*\"\n",
        "In this case we update that there are only two values in the dataset: 1 (Before 1st January 2001) and 2 (Between 1st January 2001 and 1st January 2006). We have no companies from 2006 onwards. In this case we can make the value into a 0/1 binary, indicating that the company is newly established.\n",
        "\n",
        "**Prompt:** Take the column `d3` where we have just the values 1 and 2. Convert the 1 in 0 and the 2 in 1."
      ],
      "metadata": {
        "id": "fbIMulMKfPpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['d3'] = df['d3'].replace({1: 0})\n",
        "df['d3'] = df['d3'].replace({2: 1})"
      ],
      "metadata": {
        "id": "8j_kuE-Qe_vq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_columns += ['d3']"
      ],
      "metadata": {
        "id": "43oglaZse_4X"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, to facilitate future analysis, we can extract a dataset with only the columns of interest to us."
      ],
      "metadata": {
        "id": "kFyOIluahh7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[my_columns]"
      ],
      "metadata": {
        "id": "q5dm8ZjiHYIq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis\n",
        "In this section we are going to run regressions and matching between the treated and control groups to test our hypothesis."
      ],
      "metadata": {
        "id": "PQqnUcR-Lztb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First Regression"
      ],
      "metadata": {
        "id": "Af_Ta6l_Oe3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To begin our analysis, we can consider a linear regression model using innovation intensity as the outcome variable.\n",
        "\n",
        "**Prompt:** Perform a linear regression, using the variable `intensity_score` as outcome and all the other variables as covariates. Print the summary of the model and the the level of significance of each regressors."
      ],
      "metadata": {
        "id": "qD4i454mL2ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Define the outcome variable and covariates\n",
        "outcome = 'intensity_score'\n",
        "covariates = df.drop(columns=[outcome])  # Exclude the outcome variable from the covariates\n",
        "\n",
        "# Add a constant column to the covariates (for the intercept term)\n",
        "covariates = sm.add_constant(covariates)\n",
        "\n",
        "# Fit the linear regression model\n",
        "model = sm.OLS(df[outcome], covariates)\n",
        "results = model.fit()\n",
        "\n",
        "# Print the summary of the regression model\n",
        "print(results.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP1FwqpmL1ar",
        "outputId": "2e78a001-e802-4854-b8e4-f5945062a23d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:        intensity_score   R-squared:                       0.075\n",
            "Model:                            OLS   Adj. R-squared:                  0.066\n",
            "Method:                 Least Squares   F-statistic:                     8.971\n",
            "Date:                Wed, 19 Jul 2023   Prob (F-statistic):           6.99e-53\n",
            "Time:                        09:53:52   Log-Likelihood:                -5843.3\n",
            "No. Observations:                4716   AIC:                         1.177e+04\n",
            "Df Residuals:                    4673   BIC:                         1.205e+04\n",
            "Df Model:                          42                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          1.7846      0.033     54.333      0.000       1.720       1.849\n",
            "q1_a          -0.0999      0.026     -3.844      0.000      -0.151      -0.049\n",
            "d2            -0.0208      0.014     -1.527      0.127      -0.048       0.006\n",
            "size          -0.0046      0.012     -0.378      0.706      -0.028       0.019\n",
            "Activity1      0.2150      0.028      7.770      0.000       0.161       0.269\n",
            "Activity2     -0.0206      0.059     -0.352      0.725      -0.135       0.094\n",
            "Activity3      0.5080      0.037     13.864      0.000       0.436       0.580\n",
            "Activity4      0.4535      0.037     12.223      0.000       0.381       0.526\n",
            "Activity5      0.4728      0.043     10.924      0.000       0.388       0.558\n",
            "Activity6      0.5712      0.093      6.134      0.000       0.389       0.754\n",
            "Activity7      0.0660      0.041      1.606      0.108      -0.015       0.147\n",
            "Activity8     -0.0732      0.045     -1.634      0.102      -0.161       0.015\n",
            "Activity9     -0.0625      0.069     -0.903      0.367      -0.198       0.073\n",
            "Activity10    -0.1429      0.077     -1.858      0.063      -0.294       0.008\n",
            "Activity11    -0.2025      0.121     -1.672      0.095      -0.440       0.035\n",
            "Country1       0.1282      0.065      1.975      0.048       0.001       0.255\n",
            "Country2       0.0801      0.060      1.337      0.181      -0.037       0.198\n",
            "Country3       0.0902      0.062      1.455      0.146      -0.031       0.212\n",
            "Country4      -0.1975      0.063     -3.139      0.002      -0.321      -0.074\n",
            "Country5      -0.0237      0.061     -0.387      0.699      -0.144       0.096\n",
            "Country6      -0.0562      0.061     -0.924      0.356      -0.176       0.063\n",
            "Country7       0.0069      0.060      0.114      0.909      -0.111       0.125\n",
            "Country8       0.1783      0.061      2.937      0.003       0.059       0.297\n",
            "Country9       0.1628      0.061      2.681      0.007       0.044       0.282\n",
            "Country10      0.1100      0.061      1.814      0.070      -0.009       0.229\n",
            "Country11      0.0880      0.104      0.846      0.398      -0.116       0.292\n",
            "Country12      0.0363      0.063      0.572      0.568      -0.088       0.161\n",
            "Country13     -0.0342      0.063     -0.540      0.589      -0.158       0.090\n",
            "Country14      0.2289      0.099      2.318      0.020       0.035       0.423\n",
            "Country15      0.1235      0.065      1.892      0.059      -0.004       0.251\n",
            "Country16      0.0485      0.102      0.478      0.633      -0.151       0.248\n",
            "Country17      0.0325      0.065      0.497      0.619      -0.096       0.161\n",
            "Country18      0.0717      0.061      1.185      0.236      -0.047       0.190\n",
            "Country19      0.0920      0.064      1.435      0.151      -0.034       0.218\n",
            "Country20      0.0905      0.063      1.426      0.154      -0.034       0.215\n",
            "Country21     -0.0982      0.061     -1.609      0.108      -0.218       0.021\n",
            "Country22      0.0727      0.061      1.189      0.235      -0.047       0.193\n",
            "Country23      0.0356      0.059      0.599      0.549      -0.081       0.152\n",
            "Country24     -0.0213      0.063     -0.340      0.734      -0.144       0.102\n",
            "Country25      0.1336      0.062      2.143      0.032       0.011       0.256\n",
            "Country26      0.2394      0.065      3.689      0.000       0.112       0.367\n",
            "Country27      0.1273      0.064      2.005      0.045       0.003       0.252\n",
            "Country28      0.1080      0.085      1.264      0.206      -0.060       0.276\n",
            "Country29     -0.0693      0.088     -0.785      0.433      -0.242       0.104\n",
            "d3            -0.0997      0.045     -2.218      0.027      -0.188      -0.012\n",
            "==============================================================================\n",
            "Omnibus:                        2.611   Durbin-Watson:                   1.990\n",
            "Prob(Omnibus):                  0.271   Jarque-Bera (JB):                2.692\n",
            "Skew:                           0.016   Prob(JB):                        0.260\n",
            "Kurtosis:                       3.112   Cond. No.                     1.07e+16\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 5.9e-28. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To show the results as in R with asterisks we can use the `summary_col` function of the `statsmodels` library."
      ],
      "metadata": {
        "id": "esGDQGv0OiXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.iolib.summary2 import summary_col\n",
        "\n",
        "summary_table = summary_col([results], stars=True, float_format='%.3f',)\n",
        "\n",
        "print(summary_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b6fhoFmNx-e",
        "outputId": "1e58dbea-2f3a-46f3-9d83-11fbad0e6b7e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "               intensity_score\n",
            "------------------------------\n",
            "const          1.785***       \n",
            "               (0.033)        \n",
            "q1_a           -0.100***      \n",
            "               (0.026)        \n",
            "d2             -0.021         \n",
            "               (0.014)        \n",
            "size           -0.005         \n",
            "               (0.012)        \n",
            "Activity1      0.215***       \n",
            "               (0.028)        \n",
            "Activity2      -0.021         \n",
            "               (0.059)        \n",
            "Activity3      0.508***       \n",
            "               (0.037)        \n",
            "Activity4      0.453***       \n",
            "               (0.037)        \n",
            "Activity5      0.473***       \n",
            "               (0.043)        \n",
            "Activity6      0.571***       \n",
            "               (0.093)        \n",
            "Activity7      0.066          \n",
            "               (0.041)        \n",
            "Activity8      -0.073         \n",
            "               (0.045)        \n",
            "Activity9      -0.062         \n",
            "               (0.069)        \n",
            "Activity10     -0.143*        \n",
            "               (0.077)        \n",
            "Activity11     -0.203*        \n",
            "               (0.121)        \n",
            "Country1       0.128**        \n",
            "               (0.065)        \n",
            "Country2       0.080          \n",
            "               (0.060)        \n",
            "Country3       0.090          \n",
            "               (0.062)        \n",
            "Country4       -0.197***      \n",
            "               (0.063)        \n",
            "Country5       -0.024         \n",
            "               (0.061)        \n",
            "Country6       -0.056         \n",
            "               (0.061)        \n",
            "Country7       0.007          \n",
            "               (0.060)        \n",
            "Country8       0.178***       \n",
            "               (0.061)        \n",
            "Country9       0.163***       \n",
            "               (0.061)        \n",
            "Country10      0.110*         \n",
            "               (0.061)        \n",
            "Country11      0.088          \n",
            "               (0.104)        \n",
            "Country12      0.036          \n",
            "               (0.063)        \n",
            "Country13      -0.034         \n",
            "               (0.063)        \n",
            "Country14      0.229**        \n",
            "               (0.099)        \n",
            "Country15      0.123*         \n",
            "               (0.065)        \n",
            "Country16      0.049          \n",
            "               (0.102)        \n",
            "Country17      0.033          \n",
            "               (0.065)        \n",
            "Country18      0.072          \n",
            "               (0.061)        \n",
            "Country19      0.092          \n",
            "               (0.064)        \n",
            "Country20      0.091          \n",
            "               (0.063)        \n",
            "Country21      -0.098         \n",
            "               (0.061)        \n",
            "Country22      0.073          \n",
            "               (0.061)        \n",
            "Country23      0.036          \n",
            "               (0.059)        \n",
            "Country24      -0.021         \n",
            "               (0.063)        \n",
            "Country25      0.134**        \n",
            "               (0.062)        \n",
            "Country26      0.239***       \n",
            "               (0.065)        \n",
            "Country27      0.127**        \n",
            "               (0.064)        \n",
            "Country28      0.108          \n",
            "               (0.085)        \n",
            "Country29      -0.069         \n",
            "               (0.088)        \n",
            "d3             -0.100**       \n",
            "               (0.045)        \n",
            "R-squared      0.075          \n",
            "R-squared Adj. 0.066          \n",
            "==============================\n",
            "Standard errors in\n",
            "parentheses.\n",
            "* p<.1, ** p<.05, ***p<.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whether or not a company has invested in research and development seems to have a slight negative effect on innovation intensity and be significant. If we ask ChatGPT about this fact:\n",
        "\n",
        "**Prompt:** What may indicate the fact that a firm has invested in R&D has a negative coefficient in the regression coeffient and is significant?\n",
        "\n",
        "**Answer:** It suggests that there is a negative relationship between R&D investment and the outcome variable (e.g., intensity_score). Here are a few possible interpretations or implications of a negative and significant coefficient for R&D investment:\n",
        "- Diminishing returns to R&D: ..\n",
        "- Competitive environment: ..\n",
        "- Cost considerations: .."
      ],
      "metadata": {
        "id": "KDMCIowCO9ot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matching"
      ],
      "metadata": {
        "id": "aDlBhgBlmHx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point we can calculate the propensity scores and extract the matched records.\n",
        "\n",
        "**Prompt:** Perform the propensisity score matching in the dataframe. The treatment variable is `q1_a`. In the output I expect to obtain the dataframe with the matched treatment group and the dataframe with the matched control group.\n",
        "\n",
        "In this case ChatGPT sugget to use the library `causalml`. However, this library does not appear to be installable in the colab environment (!pip install causalml).\n",
        "\n",
        "If at this point we ask them to use the library `psmpy`:\n",
        "\n",
        "**Prompt:** Perform the matching using the library `psmpy`.\n",
        "\n",
        "**Answer:** I apologize for the confusion, but as of my knowledge cutoff in September 2021, there is no widely known Python library called psmpy for propensity score matching. It's possible that the library you mentioned might be specific to a certain project or organization ...\n",
        "\n",
        "In this part of the code then we will proceed manually. We will use the classified implementation given in their documentation, without further modification. In this case we will go to perform a KNN matching."
      ],
      "metadata": {
        "id": "DqoDoPCwnWAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the library\n",
        "\n",
        "!pip install psmpy -q"
      ],
      "metadata": {
        "id": "c4NYl33cG1ad"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psmpy import PsmPy\n",
        "from psmpy.plotting import *\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "df = df.reset_index() # We add the index column\n",
        "\n",
        "psm = PsmPy(df, treatment='q1_a', indx='index')\n",
        "\n",
        "psm.logistic_ps(balance = True)\n",
        "psm.knn_matched(matcher='propensity_logit', replacement=False, caliper=None, drop_unmatched=True)\n",
        "\n",
        "treated_group = df[df['index'].isin(list(psm.matched_ids['index']))]\n",
        "control_group = df[df['index'].isin(list(psm.matched_ids['matched_ID']))]\n",
        "\n",
        "total_group = pd.concat([treated_group, control_group], ignore_index=True)\n",
        "shuffled_df = shuffle(total_group).reset_index(drop=True)\n",
        "\n",
        "matched_data = total_group.drop('index', axis=1)"
      ],
      "metadata": {
        "id": "p51ILiGbG5__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "siyiwckSmJiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now perform the regression again but considering only the matched records.\n",
        "\n",
        "**Prompt:** Perform a linear regression, using the variable `intensity_score` as outcome and all the other variables as covariates. Print the summary of the model. Use the `matched_data` dataframe."
      ],
      "metadata": {
        "id": "ZXUun0EMWR1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Define the outcome variable and covariates\n",
        "outcome = 'intensity_score'\n",
        "covariates = matched_data.drop(columns=[outcome])  # Exclude the outcome variable from the covariates\n",
        "\n",
        "# Add a constant column to the covariates (for the intercept term)\n",
        "covariates = sm.add_constant(covariates)\n",
        "\n",
        "# Fit the linear regression model\n",
        "model = sm.OLS(matched_data[outcome], covariates)\n",
        "results = model.fit()\n",
        "\n",
        "# Print the summary of the regression model\n",
        "print(results.summary())"
      ],
      "metadata": {
        "id": "KsHHfbpaWSz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_table = summary_col([results], stars=True, float_format='%.3f',)\n",
        "print(summary_table)"
      ],
      "metadata": {
        "id": "AnEXtOYvWvWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The coefficient of the our variable `q1_a` remained always significant and slightly even more negative."
      ],
      "metadata": {
        "id": "Th79fVrSWy1W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Boxplot"
      ],
      "metadata": {
        "id": "0JtR1qraKC8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a final point, we will show through boxplots the mean and dispersion of the treated group, the control group and all firms together.\n",
        "\n",
        "**Prompt:** Plot 3 boxplot, representing the the intensity_score of the treated group (dataframe treated_group), the control group (control_group), and all the firms (dataframe df). For each boxplot display also the data points with the jitter option. Use the `searborn` library."
      ],
      "metadata": {
        "id": "ETtGSMXuXKRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Prepare the data for the boxplot\n",
        "data_treated = treated_group['intensity_score']\n",
        "data_control = control_group['intensity_score']\n",
        "data_all = df['intensity_score']\n",
        "\n",
        "# Combine the data into a single dataframe\n",
        "data = pd.DataFrame({'Group': ['Treated'] * len(data_treated) +\n",
        "                              ['Control'] * len(data_control) +\n",
        "                              ['All Firms'] * len(data_all),\n",
        "                     'intensity_score': list(data_treated) + list(data_control) + list(data_all)})\n",
        "\n",
        "# Set up the figure and axes\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Create the boxplot with jittered data points\n",
        "sns.boxplot(x='Group', y='intensity_score', data=data, ax=ax)\n",
        "sns.stripplot(x='Group', y='intensity_score', data=data, jitter=True, color='black', ax=ax)\n",
        "\n",
        "# Add a title and labels to the plot\n",
        "plt.title('Intensity Score Comparison')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Intensity Score')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Owy3hO0hXwOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then with other prompts we fix the various points and arrive at the final version of the graph.\n",
        "\n",
        "**Prompt:** Reduce the data points size and add some vertical jitter.\n",
        "\n",
        "**Prompt:** For each boxplot add its data points mean as a dot. Place it hover the jitter data.\n",
        "\n",
        "Hoever it was not possible to hover the mean points. So to be visibile either enlarge the size of the dots or change the shape.\n",
        "\n",
        "**Prompt:** For the mean instead of the scatter use an horizontal line."
      ],
      "metadata": {
        "id": "Er74epcdYdUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Prepare the data for the boxplot\n",
        "data_treated = treated_group['intensity_score']\n",
        "data_control = control_group['intensity_score']\n",
        "data_all = df['intensity_score']\n",
        "\n",
        "# Combine the data into a single dataframe\n",
        "data = pd.DataFrame({'Group': ['Treated'] * len(data_treated) +\n",
        "                              ['Control'] * len(data_control) +\n",
        "                              ['All Firms'] * len(data_all),\n",
        "                     'intensity_score': list(data_treated) + list(data_control) + list(data_all)})\n",
        "\n",
        "# Set up the figure and axes\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Create the boxplot with jittered data points\n",
        "sns.boxplot(x='Group', y='intensity_score', data=data, ax=ax)\n",
        "\n",
        "jitter_amount = 0.1  # Adjust the jitter amount as desired\n",
        "num_points = len(data)\n",
        "data['jittered_intensity_score'] = data['intensity_score'] + np.random.uniform(low=-jitter_amount, high=jitter_amount, size=num_points)\n",
        "\n",
        "# Create the scatterplot with jittered data points\n",
        "sns.stripplot(x='Group', y='jittered_intensity_score', data=data, jitter=True, color='black', ax=ax, size=2,\n",
        "              dodge=True, alpha=0.5, edgecolor='gray')\n",
        "\n",
        "# Calculate the mean for each group\n",
        "mean_treated = data_treated.mean()\n",
        "mean_control = data_control.mean()\n",
        "mean_all = data_all.mean()\n",
        "\n",
        "# Plot the mean points on top of the jittered points\n",
        "# plt.scatter([0], [mean_treated], marker='o', color='red', label='Mean - Treated')\n",
        "# plt.scatter([1], [mean_control], marker='o', color='blue', label='Mean - Control')\n",
        "# plt.scatter([2], [mean_all], marker='o', color='green', label='Mean - All')\n",
        "\n",
        "plt.axhline(y=mean_treated, color='red', linestyle='--', label='Mean - Treated')\n",
        "plt.axhline(y=mean_control, color='blue', linestyle='--', label='Mean - Control')\n",
        "plt.axhline(y=mean_all, color='green', linestyle='--', label='Mean - All')\n",
        "\n",
        "# Add a legend\n",
        "plt.legend()\n",
        "\n",
        "# Add a title and labels to the plot\n",
        "plt.title('Intensity Score Comparison')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Intensity Score')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YSZsRHtoKEmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Review of ChatGPT"
      ],
      "metadata": {
        "id": "bv30lIiUikKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project ChatGPT proved to be very helpful in writing the code, and because of this it significantly sped up the time required.\n",
        "\n",
        "However, for this specific tasks, it demonstrated some limitations, and it could not have been used in complete autonomy.\n",
        "\n",
        "When it will be able to use the data directly and have a way of extracting metadata regarding the context, in this case the possible questions and answers of the questionnaire, it will have the ability to be used at a higher level and to replace the user in writing the various steps."
      ],
      "metadata": {
        "id": "_zfX9R7viyPd"
      }
    }
  ]
}